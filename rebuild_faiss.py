import os
import pickle
import pandas as pd
import numpy as np
import faiss
from dotenv import load_dotenv
from langchain_openai import OpenAIEmbeddings
from langchain_community.vectorstores import FAISS as LangChainFAISS
from langchain.schema import Document
from langchain_community.docstore.in_memory import InMemoryDocstore
from langchain_community.vectorstores.utils import DistanceStrategy

load_dotenv()

print("ğŸ”„ FAISS VeritabanÄ±nÄ± Rating ile Yeniden OluÅŸturuluyor...")
print("=" * 80)

# 1. Embeddings'leri yÃ¼kle
print("\nğŸ“‚ movie_embeddings_full.pkl yÃ¼kleniyor...")
with open('movie_embeddings_full.pkl', 'rb') as f:
    data = pickle.load(f)
    df = data['df']

total_movies = len(df)
print(f"âœ… {total_movies} film yÃ¼klendi")
print(f"ğŸ“Š Kolonlar: {df.columns.tolist()}")

# Rating kolonunu kontrol et
if 'rating' in df.columns:
    rating_col = 'rating'
elif 'rrating' in df.columns:
    rating_col = 'rrating'
elif 'Ratings' in df.columns:
    rating_col = 'Ratings'
else:
    print("âŒ Rating kolonu bulunamadÄ±!")
    exit(1)

print(f"ğŸ“Š Rating kolonu: {rating_col}")
print(f"ğŸ“Š Ã–rnek rating: {df[rating_col].iloc[0]}")

# 2. OpenAI Embeddings
api_key = os.getenv('OPENAI_API_KEY')
embeddings = OpenAIEmbeddings(
    model="text-embedding-3-small",
    openai_api_key=api_key
)

# 3. Yeni metinler oluÅŸtur - BATCH PROCESSING (Bellek dostu)
print("\nğŸ”¨ Yeni dokÃ¼manlar oluÅŸturuluyor (rating bilgisiyle)...")
print("ğŸ’¡ Bellek optimizasyonu aktif - Batch processing kullanÄ±lÄ±yor...")

texts = []
metadatas = []
embeddings_list = []

# Ä°LERLEME TAKIBI
batch_size = 50000
processed = 0

for idx in range(total_movies):
    try:
        # Tek satÄ±r al (bellekten tasarruf)
        row = df.iloc[idx]
        
        title = row.get('title', 'Bilinmiyor')
        genre = row.get('genre', '')
        emotion = row.get('emotion', '')
        review = row.get('review', '')
        rating = row.get(rating_col, 0.0)
        embedding = row.get('embedding', None)
        
        if embedding is None:
            continue
        
        # Ã–NEMLÄ°: Metin iÃ§inde rating'i aÃ§Ä±kÃ§a belirt!
        text = f"""Film: {title}
TÃ¼r: {genre}
Duygu: {emotion}
Rating: {float(rating):.1f}/10
Yorum: {str(review)[:300]}"""
        
        texts.append(text)
        metadatas.append({
            'title': title,
            'genre': str(genre),
            'emotion': emotion,
            'rating': float(rating),
            'review': str(review)[:200]
        })
        embeddings_list.append(embedding)
        
        processed += 1
        
        # Ä°lerleme gÃ¶ster
        if processed % batch_size == 0:
            print(f"  â³ {processed:,}/{total_movies:,} iÅŸlendi ({processed/total_movies*100:.1f}%)")
            
    except Exception as e:
        print(f"âš ï¸ SatÄ±r {idx} atlandÄ±: {e}")
        continue

print(f"\nâœ… Toplam {processed:,} film iÅŸlendi")

# 4. FAISS oluÅŸtur
print("\nğŸš€ FAISS index oluÅŸturuluyor...")
embeddings_array = np.array(embeddings_list).astype('float32')
dimension = len(embeddings_list[0])
index = faiss.IndexFlatL2(dimension)

# Batch halinde ekle (bellek tasarrufu)
batch_size = 100000
for i in range(0, len(embeddings_array), batch_size):
    batch = embeddings_array[i:i+batch_size]
    index.add(batch)
    print(f"  âœ… {min(i+batch_size, len(embeddings_array)):,}/{len(embeddings_array):,} eklendi")

# 5. Documents oluÅŸtur - Batch processing
print("\nğŸ“ LangChain Documents oluÅŸturuluyor...")
documents = []
for i in range(0, len(texts), 100000):
    batch_docs = [
        Document(page_content=text, metadata=meta) 
        for text, meta in zip(texts[i:i+100000], metadatas[i:i+100000])
    ]
    documents.extend(batch_docs)
    print(f"  âœ… {len(documents):,}/{len(texts):,} dÃ¶kÃ¼man oluÅŸturuldu")

# 6. Docstore oluÅŸtur
print("\nğŸ’¾ Docstore oluÅŸturuluyor...")
docstore = InMemoryDocstore({str(i): doc for i, doc in enumerate(documents)})
index_to_docstore_id = {i: str(i) for i in range(len(documents))}

# 7. LangChain FAISS
print("\nğŸ”— LangChain FAISS oluÅŸturuluyor...")
vectorstore = LangChainFAISS(
    embedding_function=embeddings,
    index=index,
    docstore=docstore,
    index_to_docstore_id=index_to_docstore_id,
    distance_strategy=DistanceStrategy.EUCLIDEAN_DISTANCE
)

# 8. KAYDET
print("\nğŸ’¾ FAISS veritabanÄ± kaydediliyor...")
vectorstore.save_local("langchain_faiss_db")

print("\n" + "=" * 80)
print("âœ… BAÅARILI! FAISS veritabanÄ± rating bilgisiyle yeniden oluÅŸturuldu!")
print("=" * 80)
print(f"\nğŸ“Š Ä°statistikler:")
print(f"  â€¢ Toplam Film: {len(documents):,}")
print(f"  â€¢ Embedding Boyutu: {dimension}")
print(f"  â€¢ Rating Kolonu: {rating_col}")
print("\nğŸ“‹ Test iÃ§in Ã¶rnek dokÃ¼man:")
print(documents[0].page_content[:250])
print(f"\nğŸ“Š Metadata Ã¶rneÄŸi:")
print(documents[0].metadata)
print("\nğŸš€ Åimdi app.py'yi Ã§alÄ±ÅŸtÄ±rabilirsiniz: streamlit run app.py")